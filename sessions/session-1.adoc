= Of Tosses and Coins
:toc: macro
:toc-title: Contents
:toclevels: 2
:toc-placement!:
:imagesdir: images
:bibtex-style: apa
:bibtex-file: references.bib
:stem:

++++
<link rel="stylesheet"  href="http://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
++++

ifndef::env-github[]
:icons: font
endif::[]

ifdef::env-github[]
:tip-caption: :bulb:
:note-caption: :information_source:
:important-caption: :heavy_exclamation_mark:
:caution-caption: :fire:
:warning-caption: :warning:
endif::[]

:theta: stem:[\theta]

image::bayes-babies.png[A Bayesian baby, width=250, align="text-center"]

[discrete]
= Bayes Babies - Session 1

---

toc::[]

== Learning Goals

The **main goal** of this session is to introduce you to the machinery of Bayesian Statistics using a very simple, but effective, toy problem.

In this session, you will:

* Build a Bayesian statistical model and explore what each component of the model is and does.
* Compute your model and perform inference: what has your model learned from the problem data?
* Criticise the model to understand if it's doing what it was built to.

This **cycle**: _Build, Compute, Critique and Repeat_ (Box's Loop) is at the core of Bayesian Statistics (and Statistics more generally) and is valid whether you're working on a toy example or doing you're own research cite:[Blei2014(3)].

[#img-boxloop]
.Taken from Blei (2014). See original caption below.
image::box_loop.svg[Box's Loop, width='75%']

.Box's Loop
[quote, David M. Blei]
____
Building and computing with models are part of an iterative process for solving data-analysis problems. This is Boxâ€™s loop, a modern interpretation of the perspective of Box (1976)
____

== Motivating problem

Consider the classic coin flip experiment: a coin is thrown into the air _n_ times and the outcome of each throw, head or tails, is recorded. The purpose of the experiment is to determine whether the coin is *unbiased*, *positively biased* (i.e. heads occur more often than tails) or *negatively biased* (i.e. tails occur more often than heads).

image::coin_flip.png[Coin Flip, width='25%']

To that extent, two different subjects toss the coin 10 times, resulting in two distinct datasets:

.Dataset A
H  T  H  H  H  T  H  H  H  T

.Dataset B
H  T  H  T  H  T  H  T  H  T


[NOTE]
====
No other information is recorded (e.g. height of toss, rotation, wind speed).
====

== Model building

. What is an adequate *random variable* (r.v.) for representing the outcomes of the experiment? Consider cases when _n_ = 1 and _n_ > 1.

. What is an adequate *likelihood* function for modelling:
	a. The outcome of a single throw
	b. The outcome of multiple throws
	c. The exact sequence of throws (give this a think and leave it for later if there is time)

+

[NOTE]
====
The *likelihood* function represents the probability of observing the data given the parameters. How likely is each dataset, assuming that the coin is unbiased? And assuming it's not?
====

+

[WARNING]
====
What notation did you use to write down the *likelihood*?
====

+

. Why did you consider your choice of *likelihood* adequate?
  a. What other parameters have you identified? We denote these by stem:[\theta].
  b. What assumptions did you make?
  c. Based on those assumptions, code up a function that represents the *data generation process*, i.e. that generates a sequence of outcomes from _n_ coin tosses according to stem:[\theta].
  d. How many different possible outcome sequences are there, as a function of _n_?

+

. Exploring the *likelihood*:
  a. Compute and plot the likelihood of each dataset, for varying values of stem:[\theta].
  b. For which values of stem:[\theta] is the likelihood at its peak? Based on this information, what would you say about the properties of the coin?
  c. Generate dummy data for an unbiased coin, using your *data generation algorithm*. Simulate 100 experiments (datasets) of _n_ = 10. Note that stem:[\theta] should be constant.
  d. Compute and plot the likelihood for the simulated datasets of an unbiased coin.
  e. Add an additional layer on top of this last plot: the likelihood of datasets _A_ and _B_ given that the coin is unbiased. What do you observe?

+

[WARNING]
====
When simulating data, make sure you use a *seed* so that other can reproduce your dummy data and we can compare results among each other. Please use the seed = 1337 when generating random numbers.
====

+

. Exploring the *prior*:
  a. Identify at least two priors for stem:[\theta]:
  b. What is the intuition behind each of the priors? What prior knowledge are they encoding?
  c. How do the priors differ? Which prior is more informative and which is less?
  d. The priors are probability distributions and hence they also have parameters. These are called _hyperparameters_ and we denote them by stem:[\alpha].
  e. Choose a value for each _hyperparameter_ in stem:[\alpha]. Why did you choose these values?
  f. Compute and plot the priors for stem:[\theta], using the values you chose for stem:[\alpha].

+

[NOTE]
====
Informally, a prior represents the probability of a parameter before observing the data. A few things to consider when choosing a prior (as it is a probability distribution):

* Is the parameter continuous or discrete?
* Does the parameter take only strictly positive values?
* Are its values bounded between a specific interval (e.g. [0,1])?
====

+

[WARNING]
====
What notation did you use to write down the *prior*?
====

+

. Write down what your final model looks like: parameters, likelihood, priors and hyperparameters.


. Think about the *posterior*, using the intuition developed above:
  a. Put the plots of the prior and the likelihood (for your dummy data) side by side. What shape do you expect the posterior to have when a coin is unbiased according to your model?
  b. How will the posterior differ for each of the priors identified above?
  c. What effect do you think that the size of the sequence _n_ has on the posterior?
  d. What is the job and the intuition behind the denominator term when computing the posterior?
  e. Does the denominator have any influence on determining the shape of the posterior?

+
[NOTE]
====
The posterior is the probability of the parameters given the data (or evidence) and is proportional to the *likelihood* times the *prior*.
====

== Model inference

[start=8]
. Compute the posterior using *grid approximation* cite:[McElreath2015(39-40)].
  a. Use a grid with a small number of points (e.g. 5) and a grid with a larger number of points (e.g. 20).
  b. Plot the posterior distribution in each of the two cases.
  c. How good is one approximation compared to the other?

+
[TIP]
====
* See (McElrath, 2015, pp. 39-40) for an explanation and example.
====

+

. Draw 10,000 samples from the posterior.
  a. Plot the samples and their density/histogram.
  b. What is the point of sampling from the posterior?
  c. Compute the following point estimates: maximum a posteriori (MAP), mean, median.
  d. What is the intuition behind each of the point estimates above?


== Model criticism

[start=9]
. Compute the *posterior predictive distribution*

[TIP]
====
Have a look at:

  - https://stats.stackexchange.com/q/115157[this] stackexchange thread.
  - https://www.cs.princeton.edu/courses/archive/fall11/cos597C/lectures/ppc.pdf[David Blei] on posterior predictive checks
====

== Discussion

Consider the following scenarios:

* Imagine that the coin has magic properties and that the probability of heads changes every 5 tosses.

* Imagine that instead of the single coin, there are several coins with different properties to choose from at each trial:
  - You would pick one coin at random, toss it and record the outcome.
  - Someone else picks one coin, tosses it and tells you the outcome. You can't see which coin was tossed but you are told the outcome.

How do you think your model would perform in each scenario? How would you rebuild your model in light of this new information?

== Recommended Reading

* cite:[McElreath2015] -- Chapters 2 and 3
* cite:[Lambert2018] -- Chapters 2, 4 and 5
* cite:[Pilon2015] -- Chapter 1

== References

bibliography::[]
